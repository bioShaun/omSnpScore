#!/usr/bin/env python3

import sys
import attr
import fire
import yaml
import numpy as np
import pandas as pd
from tqdm import tqdm
from addict import Dict
from loguru import logger
from pandas import Series
from pathlib import Path
from sqlalchemy import create_engine

ANN_TABLE_COL = ("chrom", "pos", "ref", "alt", "INFO")


def getAnn(info):
    return info.split('ANN=')[1]


@attr.s
class AnnDb:
    ann_df = attr.ib()
    postgres_cfg = attr.ib(converter=Path)

    def __attrs_post_init__(self):
        self.cfg = self.loadCfg()
        self.engine = self.createEngine()
        self.db_df = self.loadDb()

    def createEngine(self):
        return create_engine(
            f'postgresql+psycopg2://{self.cfg.postgres_user}:{self.cfg.postgres_password}@{self.cfg.postgres_host}:{self.cfg.postgres_port}/{self.cfg.postgres_datebase}'
        )

    def loadCfg(self):
        if self.postgres_cfg.is_file():
            with open(self.postgres_cfg) as cfg:
                return Dict(yaml.full_load(cfg))
        else:
            sys.exit('postgres config not found!')

    def loadDb(self):
        logger.info('Loading annotation from db ...')
        sql_db = pd.io.sql.SQLDatabase(self.engine)
        if sql_db.has_table(self.cfg.postgres_table):
            sql_command = f"select * from {self.cfg.postgres_table}"
            return pd.read_sql(sql_command, self.engine)
        else:
            return pd.DataFrame([])

    def saveNewRecord(self):
        if self.db_df.empty:
            logger.info('db is empty ...')
            new_df = self.ann_df
        else:
            merged_df = self.db_df.merge(self.ann_df, how='outer')
            new_df = merged_df[merged_df.feature.isna()].drop(
                ['feature', 'gene', 'hgvs'], axis=1)
        flat_df = flatAnnotation(new_df)
        logger.info(f'saving {len(flat_df)} records ...')
        flat_df.to_sql(self.cfg.postgres_table,
                       self.engine,
                       if_exists='append',
                       index=False,
                       chunksize=10000)


def new_hgvsP(arrLike, hgvs_p, tr):
    if arrLike[hgvs_p]:
        return f'{arrLike[tr]}|{arrLike[hgvs_p]}'
    else:
        return arrLike[hgvs_p]


def flatAnnotation(df, bulk=10 * 1000):
    nRows = len(df)
    flat_dfs = []
    for i in tqdm(range(0, nRows, bulk)):
        start = i
        end = i + bulk
        ann_df = df[start:end]
        print(start, end)
        print(ann_df[:5])
        ann_df = ann_df.set_index(["chrom", "pos", "ref", "alt"])
        logger.info('Flat annotation records ...')
        ann_df = ann_df.INFO.str.split(',').apply(Series).unstack(
            level=[0, 1, 2, 3]).dropna()
        ann_df = ann_df.str.split('|').apply(Series).loc[:, [1, 4, 6, 10]]
        ann_df.columns = ['feature', 'gene', 'transcript', 'HGVS.P.OLD']
        ann_df = ann_df[~ann_df.feature.isna()]
        ann_df = ann_df.reset_index()
        logger.info('Add transcript id to HGVS.P ...')
        ann_df.loc[:, 'hgvs'] = ann_df.apply(new_hgvsP,
                                             axis=1,
                                             args=('HGVS.P.OLD', 'transcript'))
        logger.info(
            'Remove duplicated records according to Gene Level annotation ...')
        ann_df = ann_df.loc[:, [
            "chrom", "pos", "ref", "alt", 'feature', 'gene', 'hgvs'
        ]]
        ann_df.drop_duplicates(inplace=True)
        flat_dfs.append(ann_df)
    return pd.concat(flat_dfs)


def cleanVcfAnn(vcf, ann=None, test=False, postgres_cfg=None):
    logger.info('Loading vcf file ...')
    ann_df = pd.read_csv(vcf, sep='\t', header=None, comment="#")
    if test:
        logger.info('Extract test items ...')
        ann_df = ann_df[:100000]
    ann_df = ann_df.loc[:, [0, 1, 3, 4, 7]]
    ann_df.columns = ANN_TABLE_COL
    ann_df.loc[:, 'INFO'] = ann_df.INFO.map(getAnn)

    if postgres_cfg:
        anndbObj = AnnDb(ann_df, postgres_cfg)
        anndbObj.saveNewRecord()
    elif ann:
        flat_df = flatAnnotation(ann_df)
        flat_df.to_csv(ann, index=False)
    else:
        print(ann_df[:5])


if __name__ == "__main__":
    fire.Fire(cleanVcfAnn)