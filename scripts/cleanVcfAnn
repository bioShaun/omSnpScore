#!/usr/bin/env python3

from logging import error
import re
from re import search
import sys
import attr
import fire
import sqlalchemy
import yaml
import pandas as pd
from tqdm import tqdm
from typing import List, Union
from addict import Dict
from loguru import logger
from pandas import Series
from pathlib import Path
from sqlalchemy import create_engine
from pandarallel import pandarallel

pandarallel.initialize(nb_workers=8)

ANN_TABLE_COL = ("chrom", "pos", "ref", "alt", "INFO")
SNPEFF_ANN_FIELD = ('effect', 'putative_impact', 'gene_name', 'gene_id',
                    'feature_type', 'feature_id', 'transcript_biotype', 'exon',
                    'hgvs_c', 'hgvs_p', 'cdna_pos', 'cds_pos', 'protein_pos',
                    'dis_to_feature', 'errors')
LOF_PATTERN = re.compile(r';(LOF=\S+)$')
ANN_PATTERN1 = re.compile(r'ANN=(\S+?);')
ANN_PATTERN2 = re.compile(r'ANN=(\S+?)$')


def getAnn(info):
    def _extractAnn(pattern) -> Union[str, None]:
        nonlocal info
        search_res = pattern.search(info)
        if search_res:
            return search_res.groups()[0]

    if LOF_PATTERN.search(info):
        return _extractAnn(ANN_PATTERN1)
    else:
        return _extractAnn(ANN_PATTERN2)


def getLof(info) -> Union[str, None]:
    search_res = LOF_PATTERN.search(info)
    if search_res:
        return search_res.groups()[0]


def annStr2List(annLine: str) -> List[str]:
    return annLine.split('|')[1:]


@attr.s(auto_attribs=True)
class AnnDb:
    ann_df: pd.DataFrame
    lof_nmd_df: pd.DataFrame
    postgres_cfg: Path

    def __attrs_post_init__(self) -> None:
        self.cfg = self.loadCfg()
        self.engine = self.createEngine()
        self.lastId = 0

    def createEngine(self) -> sqlalchemy.engine.base.Engine:
        return create_engine(
            f'postgresql+psycopg2://{self.cfg.postgres_user}:{self.cfg.postgres_password}@{self.cfg.postgres_host}:{self.cfg.postgres_port}/{self.cfg.postgres_datebase}'
        )

    def loadCfg(self) -> Dict:
        if self.postgres_cfg.is_file():
            with open(self.postgres_cfg) as cfg:
                return Dict(yaml.full_load(cfg))
        else:
            sys.exit('postgres config not found!')

    def loadLocusDb(self, condition="") -> pd.DataFrame:
        logger.info('Loading locus from db ...')
        sql_db = pd.io.sql.SQLDatabase(self.engine)
        if sql_db.has_table(self.cfg.locus_table):
            sql_command = f"select * from {self.cfg.locus_table} {condition}"
            return pd.read_sql(sql_command, self.engine)
        else:
            return pd.DataFrame([])

    def novelSnpLocus(self) -> pd.DataFrame:
        self.snpLocus_df = self.loadLocusDb()
        if self.snpLocus_df.empty:
            return self.ann_df
        else:
            merged_df = self.snpLocus_df.merge(self.ann_df, how='right')
            novel_df = merged_df[merged_df['id'].isna()]
            self.lastId = max(self.snpLocus_df['id'])
            return novel_df

    def saveSnpLocus(self):
        novel_df = self.novelSnpLocus()
        if novel_df.empty:
            logger.info(f'No novel locus ...')
        else:
            logger.info(f'saving {len(novel_df)} locus ...')
            novel_locus_df = novel_df.loc[:, ANN_TABLE_COL[:-1]]
            novel_locus_df.to_sql(self.cfg.locus_table,
                                  self.engine,
                                  if_exists='append',
                                  index=False,
                                  chunksize=10000)
            self.saveNewRecord()

    def saveNewRecord(self) -> None:
        sql_condition = f"where id>{self.lastId}"
        novel_locus_db_df = self.loadLocusDb(condition=sql_condition)
        merge_df = novel_locus_db_df.merge(self.ann_df, how='left')
        if (len(merge_df[merge_df['INFO'].isna()])):
            logger.error('Novel snp without annotation.')
            sys.exit(1)

        novel_ann_df = merge_df[~merge_df['id'].isna()].copy()
        novel_ann_df.drop(list(ANN_TABLE_COL[:-1]), axis=1, inplace=True)
        novel_ann_df.columns = ['snpId', 'INFO']
        flat_df = flatAnnotation(novel_ann_df)

        logger.info(f'saving {len(flat_df)} annotation records ...')
        flat_df.to_sql(self.cfg.ann_table,
                       self.engine,
                       if_exists='append',
                       index=False,
                       chunksize=10000)

        if not self.lof_nmd_df.empty:
            lof_merged_df = novel_locus_db_df.merge(self.lof_nmd_df,
                                                    how='right')
            novel_lof_df = lof_merged_df[~lof_merged_df['id'].isna()].copy()
            novel_lof_df.drop(list(ANN_TABLE_COL[:-1]), axis=1, inplace=True)
            novel_lof_df.columns = ['snpId', 'lof_nmd']

            logger.info(f'saving {len(novel_lof_df)} lof records ...')
            novel_lof_df.to_sql(self.cfg.lof_table,
                                self.engine,
                                if_exists='append',
                                index=False,
                                chunksize=10000)


def flatAnnotation(df: pd.DataFrame, bulk=10 * 10000) -> pd.DataFrame:
    nRows = len(df)
    flat_dfs = []
    if nRows:
        for i in tqdm(range(0, nRows, bulk)):
            start = i
            end = i + bulk
            ann_df = df[start:end]
            ann_df = ann_df.set_index(["snpId"])
            logger.info('Flat annotation records ...')
            ann_df = ann_df.INFO.str.split(',').parallel_apply(
                Series).unstack().dropna()
            ann_df = ann_df.parallel_map(annStr2List).parallel_apply(Series)
            ann_df.columns = SNPEFF_ANN_FIELD
            ann_df = ann_df[~ann_df.effect.isna()]
            ann_df = ann_df.reset_index()
            ann_df.drop(['level_0'], axis=1, inplace=True)
            flat_dfs.append(ann_df)
        return pd.concat(flat_dfs)
    else:
        return pd.DataFrame([])


def cleanVcfAnn(vcf: str, ann=None, test=False, postgres_cfg=None) -> None:
    logger.info('Loading vcf file ...')
    ann_df = pd.read_csv(vcf, sep='\t', header=None, comment="#")
    if test:
        logger.info('Extract test items ...')
        ann_df = ann_df[:1000]
    ann_df = ann_df.loc[:, [0, 1, 3, 4, 7]]
    ann_df.columns = ANN_TABLE_COL
    lof_nmd_df = ann_df.copy()
    ann_df.loc[:, 'INFO'] = ann_df.INFO.parallel_map(getAnn)
    lof_nmd_df.loc[:, 'lof_nmd'] = lof_nmd_df.INFO.parallel_map(getLof)
    lof_nmd_df.drop('INFO', axis=1, inplace=True)
    lof_nmd_df.dropna(inplace=True)

    if postgres_cfg:
        anndbObj = AnnDb(ann_df, lof_nmd_df, Path(postgres_cfg))
        anndbObj.saveSnpLocus()
    elif ann:
        flat_df = flatAnnotation(ann_df)
        flat_df.to_csv(ann, index=False)
    else:
        print(ann_df[:5])
        print(lof_nmd_df[:5])


if __name__ == "__main__":
    fire.Fire(cleanVcfAnn)